<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Sound Visualization</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background-color: black;
    }
    canvas {
      display: block;
    }
  </style>
</head>
<body>
  <canvas id="visualizer"></canvas>

  <script>
    const canvas = document.getElementById("visualizer");
    const ctx = canvas.getContext("2d");

    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;

    let width = canvas.width;
    let height = canvas.height;

    // Resize canvas on window resize
    window.addEventListener("resize", () => {
      canvas.width = window.innerWidth;
      canvas.height = window.innerHeight;
      width = canvas.width;
      height = canvas.height;
    });

    // Set up audio context
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const analyser = audioCtx.createAnalyser();
    analyser.fftSize = 256;

    const dataArray = new Uint8Array(analyser.frequencyBinCount);

    // Visualization logic
    function draw() {
      ctx.clearRect(0, 0, width, height);

      analyser.getByteFrequencyData(dataArray);

      const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

      if (average > 10) {
        // Draw vertical wave lines when sound is detected
        const barWidth = width / dataArray.length;
        dataArray.forEach((value, index) => {
          const barHeight = (value / 255) * height;
          const x = index * barWidth;

          ctx.fillStyle = `rgb(${value}, ${255 - value}, 255)`;
          ctx.fillRect(x, height - barHeight, barWidth, barHeight);
        });
      } else {
        // Draw a horizontal line when no sound
        ctx.strokeStyle = "cyan";
        ctx.lineWidth = 4;
        ctx.beginPath();
        ctx.moveTo(0, height / 2);
        ctx.lineTo(width, height / 2);
        ctx.stroke();
      }

      requestAnimationFrame(draw);
    }

    // Access microphone and start visualization
    async function setupAudio() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const source = audioCtx.createMediaStreamSource(stream);
        source.connect(analyser);

        draw(); // Start visualization
      } catch (err) {
        console.error("Microphone access denied:", err);
      }
    }

    setupAudio();
  </script>
</body>
</html>
